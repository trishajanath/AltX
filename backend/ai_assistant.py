import google.generativeai as genai
import os
from typing import List, Dict, Optional, ClassVar, Union
from dotenv import load_dotenv
from github import Github
from github.GithubException import GithubException
from dataclasses import dataclass

# --- PHASE 1 IMPORTS ---
import git
import shutil
from pathlib import Path
from scanner.secrets_detector import scan_secrets
from scanner.static_python import run_bandit # --- PHASE 1B ---

# Updated RepoAnalysis class to handle both formats
@dataclass
class RepoAnalysis:
    """Store repository analysis results."""
    repo_name: str
    description: str
    language: str
    files_scanned: List[str]
    security_findings: List[str]
    open_issues: int
    # Updated to handle both dict (new comprehensive format) and RepoAnalysis (legacy format)
    latest_analysis: ClassVar[Optional[Union[Dict, 'RepoAnalysis']]] = None

# Load environment variables from a .env file
load_dotenv()

# Available models configuration
AVAILABLE_MODELS = {
    'fast': 'models/gemini-2.5-flash',
    'smart': 'models/gemini-2.5-pro'
}

# --- Initialize API Clients ---
models = {}
GITHUB_TOKEN = os.getenv("GITHUB_PAT")

if GITHUB_TOKEN:
    try:
        github_client = Github(GITHUB_TOKEN)
        test_user = github_client.get_user()
        print(f"âœ… GitHub client initialized for user: {test_user.login}")
    except Exception as e:
        print(f"âŒ GitHub client initialization failed: {e}")
        github_client = Github()
        print("âš ï¸ Falling back to anonymous GitHub access")
else:
    github_client = Github()
    print("âš ï¸ GitHub client initialized without token (public repos only)")

try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("No API key found. Set the GOOGLE_API_KEY environment variable.")
    
    genai.configure(api_key=api_key)
    
    for model_type, model_name in AVAILABLE_MODELS.items():
        try:
            models[model_type] = genai.GenerativeModel(model_name)
            print(f"âœ… Initialized {model_type} model ({model_name})")
        except Exception as e:
            print(f"âŒ Failed to initialize {model_type} model: {e}")
            
except Exception as e:
    print(f"âŒ Error initializing Gemini API: {e}")

# --- Helper functions ---
def get_model(model_type: str = 'fast') -> Optional[genai.GenerativeModel]:
    """Get the specified model (fast or smart)"""
    return models.get(model_type)

def format_chat_response(text: str) -> str:
    """Format AI response for better readability"""
    import re
    formatted = text.strip()
    formatted = re.sub(r'<[^>]+>', '', formatted)
    formatted = formatted.replace('&nbsp;', ' ').replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
    formatted = re.sub(r'---+', '', formatted)
    formatted = re.sub(r'â•â•â•+', '', formatted)
    formatted = re.sub(r'\n\s*\n\s*\n', '\n\n', formatted)
    emojis = ['âœ…', 'âŒ', 'âš ï¸', 'ğŸš¨', 'ğŸ“Š', 'ğŸ”’', 'ğŸ›¡ï¸', 'ğŸ”', 'ğŸŒ', 'ğŸ¯', 'âš¡', 'ğŸ“‚', 'ğŸ”']
    for emoji in emojis:
        formatted = formatted.replace(emoji, f'\n{emoji}')
    formatted = re.sub(r'(##?\s*[ğŸ›¡ï¸ğŸš¨âš ï¸âœ…âŒğŸ“ŠğŸ¯âš¡ğŸ“‚ğŸ”].*)', r'\n\n\1', formatted)
    while '\n\n\n' in formatted:
        formatted = formatted.replace('\n\n\n', '\n\n')
    formatted = formatted.lstrip('\n')
    return formatted

def get_chat_response(history: List[Dict], model_type: str = 'fast') -> str:
    """Enhanced chat response with model selection and comprehensive context"""
    model = get_model(model_type)
    if model is None:
        return f"âŒ **AI model ({model_type}) is not available**"

    try:
        # Enhanced context based on model type
        if model_type == 'smart':
            context = """You are GitHub Copilot, an expert cybersecurity consultant and code analysis specialist. You provide comprehensive, detailed security analysis with:

ğŸ›¡ï¸ **Advanced Security Analysis:**
â€¢ Deep threat assessment and risk evaluation
â€¢ Comprehensive vulnerability analysis with CVSS scoring context
â€¢ Advanced remediation strategies with implementation details
â€¢ Compliance and regulatory guidance (OWASP, NIST, SOC2)
â€¢ Architecture-level security recommendations

ğŸ”¬ **Expert Code Review:**
â€¢ Detailed static analysis interpretation with business impact
â€¢ Complex dependency vulnerability assessment
â€¢ Advanced secure coding pattern recommendations
â€¢ Performance vs security trade-off analysis
â€¢ Enterprise-grade security implementation guidance

ğŸ’¡ **Communication Style:**
â€¢ Provide comprehensive, detailed explanations
â€¢ Include technical depth with practical examples
â€¢ Reference industry standards and best practices
â€¢ Give step-by-step implementation guides
â€¢ Explain the 'why' behind each recommendation
â€¢ Use technical terminology appropriately"""
        else:  # fast model
            context = """You are GitHub Copilot, a friendly cybersecurity assistant focused on quick, actionable security guidance:

ğŸ”’ **Quick Security Analysis:**
â€¢ Fast vulnerability identification and prioritization
â€¢ Clear, concise remediation steps
â€¢ Immediate action items and quick wins
â€¢ Essential security best practices
â€¢ Rapid threat assessment

âš¡ **Efficient Communication:**
â€¢ Provide clear, concise recommendations
â€¢ Focus on high-impact, easy-to-implement fixes
â€¢ Use simple, actionable language
â€¢ Prioritize critical issues first
â€¢ Give practical examples and code snippets
â€¢ Be encouraging and supportive"""
        
        # Add current analysis context if available
        if RepoAnalysis.latest_analysis:
            if isinstance(RepoAnalysis.latest_analysis, dict):
                # Handle new comprehensive analysis format from /analyze-repo
                repo_info = RepoAnalysis.latest_analysis.get('repository_info', {})
                security_summary = RepoAnalysis.latest_analysis.get('security_summary', {})
                
                if model_type == 'smart':
                    context += f"""

ğŸ“‚ **COMPREHENSIVE REPOSITORY CONTEXT:**
**Repository:** {repo_info.get('name', 'Unknown')} ({repo_info.get('language', 'Unknown')})
**Description:** {repo_info.get('description', 'No description')}
**Security Score:** {RepoAnalysis.latest_analysis.get('overall_security_score', 'N/A')}/100 ({RepoAnalysis.latest_analysis.get('security_level', 'Unknown')})

**DETAILED SECURITY METRICS:**
â€¢ Files Scanned: {security_summary.get('total_files_scanned', 0)}
â€¢ Sensitive Files: {security_summary.get('sensitive_files_found', 0)}
â€¢ Hardcoded Secrets: {security_summary.get('secrets_found', 0)}
â€¢ Static Analysis Issues: {security_summary.get('static_issues_found', 0)}
â€¢ Vulnerable Dependencies: {security_summary.get('vulnerable_dependencies', 0)}
â€¢ Code Quality Issues: {security_summary.get('code_quality_issues', 0)}
â€¢ Security Files Present: {security_summary.get('security_files_present', 0)}

**CRITICAL FINDINGS SUMMARY:**
â€¢ Secret Scan: {len(RepoAnalysis.latest_analysis.get('secret_scan_results', []))} secrets detected
â€¢ Code Quality: {len(RepoAnalysis.latest_analysis.get('code_quality_results', []))} patterns found
â€¢ Dependencies: {len(RepoAnalysis.latest_analysis.get('dependency_scan_results', {}).get('vulnerable_packages', []))} vulnerable packages
â€¢ Static Analysis: {len(RepoAnalysis.latest_analysis.get('static_analysis_results', []))} issues found

**TOP RECOMMENDATIONS:**
{chr(10).join([f'â€¢ {rec}' for rec in RepoAnalysis.latest_analysis.get('recommendations', [])[:5]])}

**RECENT FINDINGS DETAILS:**
{chr(10).join([f'â€¢ {finding.get("file", "unknown")}: {finding.get("description", "Security issue")}' for finding in RepoAnalysis.latest_analysis.get('secret_scan_results', [])[:3]])}
{chr(10).join([f'â€¢ {finding.get("file", "unknown")}: {finding.get("pattern", "unknown")} ({finding.get("severity", "unknown")} severity)' for finding in RepoAnalysis.latest_analysis.get('code_quality_results', [])[:3]])}"""
                else:  # fast model
                    context += f"""

ğŸ“‚ **REPOSITORY CONTEXT:**
**Repository:** {repo_info.get('name', 'Unknown')} - Security Score: {RepoAnalysis.latest_analysis.get('overall_security_score', 'N/A')}/100
**Key Issues:** {security_summary.get('secrets_found', 0)} secrets, {security_summary.get('code_quality_issues', 0)} code issues, {security_summary.get('vulnerable_dependencies', 0)} vulnerable deps
**Priority Actions:** {', '.join(RepoAnalysis.latest_analysis.get('recommendations', [])[:2])}"""
            else:
                # Handle legacy RepoAnalysis format
                context += f"""

ğŸ“‚ **REPOSITORY CONTEXT:**
**Repository:** {RepoAnalysis.latest_analysis.repo_name}
**Language:** {RepoAnalysis.latest_analysis.language}
**Security Findings:** {len(RepoAnalysis.latest_analysis.security_findings)} issues found
**Recent Findings:** {', '.join(RepoAnalysis.latest_analysis.security_findings[:3])}"""
        
        # Build conversation history with proper error handling
        formatted_history = [{'parts': [{'text': context}], 'role': 'model'}]
        for msg in history:
            try:
                # Handle different message formats
                if isinstance(msg.get('parts'), list):
                    # Handle parts as list of dicts: [{"text": "content"}]
                    if len(msg['parts']) > 0 and isinstance(msg['parts'][0], dict):
                        content = msg['parts'][0].get('text', '')
                    # Handle parts as list with string: ["content"]
                    elif len(msg['parts']) > 0 and isinstance(msg['parts'][0], str):
                        content = msg['parts'][0]
                    else:
                        content = str(msg.get('parts', ''))
                elif isinstance(msg.get('parts'), dict):
                    # Handle parts as single dict: {"text": "content"}
                    content = msg['parts'].get('text', '')
                elif isinstance(msg.get('parts'), str):
                    # Handle parts as string: "content"
                    content = msg['parts']
                else:
                    # Fallback: try to get message content from other fields
                    content = msg.get('message', msg.get('content', str(msg.get('parts', ''))))
                
                role = 'user' if msg.get('type') == 'user' or msg.get('role') == 'user' else 'model'
                formatted_history.append({'parts': [{'text': str(content)}], 'role': role})
            except Exception as e:
                print(f"Warning: Error processing message in history: {e}")
                # Skip malformed messages
                continue

        # Use selected model for response
        chat = model.start_chat(history=formatted_history[:-1])
        last_message = formatted_history[-1]['parts'][0]['text']
        response = chat.send_message(last_message)
        
        # Enhanced response formatting based on model type
        formatted_response = format_chat_response(response.text.strip())
        
        if model_type == 'smart':
            # Add model indicator for comprehensive responses
            return f"ğŸ§  **Comprehensive Analysis** (Smart Model)\n\n{formatted_response}"
        else:
            # Add model indicator for quick responses
            return f"âš¡ **Quick Analysis** (Fast Model)\n\n{formatted_response}"
        
    except Exception as e:
        return f"âŒ **Chat Error ({model_type} model):** {str(e)}"
# --- Main Analysis Function ---
def analyze_github_repo(repo_url: str, model_type: str = 'smart') -> str:
    """Analyze GitHub repository with model selection"""
    if not github_client:
        return "âŒ **GitHub client not available.** Please check your setup."
    
    repo_name_from_url = repo_url.rstrip('/').split('/')[-1].replace('.git', '')
    local_repo_path = f"/tmp/{repo_name_from_url}"

    try:
        repo_url = repo_url.rstrip('/').replace('.git', '')
        parts = repo_url.split('/')
        if len(parts) < 5 or parts[2].lower() != 'github.com':
            return "âŒ **Invalid repository URL format.**"
        
        owner, repo_name = parts[-2], parts[-1]
        repo = github_client.get_repo(f"{owner}/{repo_name}")
        
        print(f"Cloning {repo_url} to {local_repo_path}...")
        if Path(local_repo_path).exists():
            shutil.rmtree(local_repo_path)
        git.Repo.clone_from(repo_url, local_repo_path)

        security_findings = []
        all_files_visited = [str(p.relative_to(local_repo_path)) for p in Path(local_repo_path).rglob("*") if p.is_file()]
        
        # --- Run Secret Scanner (Phase 1A) ---
        print("ğŸ” Scanning for hardcoded secrets...")
        hardcoded_secrets = scan_secrets(local_repo_path)
        if hardcoded_secrets:
            security_findings.append(f"ğŸš¨ CRITICAL: Found {len(hardcoded_secrets)} hardcoded secrets!")
            for secret in hardcoded_secrets:
                security_findings.append(f"   - Type: {secret['type']} in file: `{secret['file']}`")
        
        # --- PHASE 1B: Run Bandit Static Analysis ---
        print("ğŸ Scanning Python code with Bandit...")
        static_issues = run_bandit(local_repo_path)
        if static_issues:
            security_findings.append(f"ğŸ›¡ï¸ Found {len(static_issues)} potential issues in Python code via Bandit.")
            for issue in static_issues:
                # To avoid clutter, let's focus on medium/high severity issues
                if issue['severity'] in ['MEDIUM', 'HIGH']:
                    security_findings.append(f"   - {issue['severity']}: {issue['issue']} in `{issue['filename']}` (Line: {issue['line_number']})")
        print(f"âœ… Scans complete. Found {len(hardcoded_secrets)} secrets and {len(static_issues)} static issues.")

        # --- Store Analysis Results (Legacy format for backward compatibility) ---
        RepoAnalysis.latest_analysis = RepoAnalysis(
            repo_name=repo.full_name,
            description=repo.description or 'No description',
            language=repo.language or 'Unknown',
            files_scanned=all_files_visited,
            security_findings=security_findings,
            open_issues=repo.open_issues_count
        )
        
        # --- Build AI Analysis Prompt with Model-Specific Detail Level ---
        secret_findings_summary = "\n".join([f"â€¢ {s}" for s in security_findings if "secret" in s.lower()])
        static_findings_summary = "\n".join([f"â€¢ {s}" for s in security_findings if "Bandit" in s or "Python code" in s])

        if model_type == 'smart':
            security_prompt = f"""
**COMPREHENSIVE REPOSITORY SECURITY ANALYSIS REQUEST**
Perform a detailed security analysis of the GitHub repository below based on comprehensive scan results.

**ğŸ“Š Repository Information:**
â€¢ **Name:** {repo.full_name}
â€¢ **Description:** {repo.description or 'No description provided'}
â€¢ **Primary Language:** {repo.language or 'Unknown'}
â€¢ **Open Issues:** {repo.open_issues_count}
â€¢ **Files Scanned:** {len(all_files_visited)}

**ğŸ”‘ Hardcoded Secrets Analysis:**
{secret_findings_summary if secret_findings_summary else "â€¢ âœ… No hardcoded secrets were detected in the repository."}

**ğŸ Python Static Code Analysis (Bandit):**
{static_findings_summary if static_findings_summary else "â€¢ âœ… No medium or high-severity static analysis issues found in Python code."}

Please provide a comprehensive, detailed analysis with these sections:

## ğŸ›¡ï¸ Executive Security Summary
Provide a detailed security posture assessment with risk rating and strategic recommendations.

## ğŸš¨ Critical Vulnerabilities Assessment
Detailed analysis of each critical issue with:
- CVSS risk scoring context
- Potential attack vectors
- Business impact assessment
- Exploitation scenarios

## ğŸ”¬ Technical Risk Analysis
In-depth technical evaluation including:
- Code quality implications
- Architecture security considerations
- Dependency management risks
- Configuration security gaps

## ğŸ¯ Prioritized Remediation Roadmap
Detailed action plan with:
- Immediate critical fixes (0-24 hours)
- Short-term improvements (1-4 weeks)  
- Long-term security strategy (1-6 months)
- Implementation complexity assessment

## ğŸ’¡ Advanced Security Recommendations
Enterprise-grade recommendations including:
- Security architecture improvements
- DevSecOps integration strategies
- Compliance considerations (OWASP, NIST)
- Monitoring and alerting strategies

**ANALYSIS REQUIREMENTS:**
â€¢ Provide comprehensive technical depth with practical examples
â€¢ Include specific code examples and implementation guides
â€¢ Reference industry standards and best practices
â€¢ Explain the business rationale behind each recommendation
â€¢ Use professional security consultant terminology
"""
        else:  # fast model
            security_prompt = f"""
**QUICK REPOSITORY SECURITY SCAN ANALYSIS**
Analyze this GitHub repository and provide fast, actionable security guidance.

**ğŸ“Š Repository:** {repo.full_name} ({repo.language or 'Unknown'})

**ğŸ”‘ Secrets Scan:**
{secret_findings_summary if secret_findings_summary else "â€¢ âœ… No secrets found"}

**ğŸ Code Analysis:**
{static_findings_summary if static_findings_summary else "â€¢ âœ… No major issues found"}

Please provide a quick analysis with these sections:

## ğŸ›¡ï¸ Security Summary
Quick security rating and main concerns.

## ğŸš¨ Critical Issues
List the most important problems to fix immediately.

## âš¡ Quick Fixes
Specific, actionable steps you can implement today.

## ğŸ¯ Next Steps
Simple recommendations for improving security.

**REQUIREMENTS:**
â€¢ Keep responses concise and actionable
â€¢ Focus on high-impact, easy-to-implement fixes
â€¢ Provide specific examples and commands
â€¢ Use simple, clear language
"""
        
        history = [{"type": "user", "parts": [{"text": security_prompt}]}]
        return get_chat_response(history, model_type)

    except Exception as e:
        print(f"Error analyzing repository: {str(e)}")
        return f"âŒ **An unexpected error occurred:** {str(e)}"
    finally:
        if Path(local_repo_path).exists():
            shutil.rmtree(local_repo_path)

def analyze_scan_with_llm(https: bool, flags: List[str], headers: Dict[str, str], model_type: str = 'fast') -> str:
    """Analyze website scan results using LLM with model selection"""
    model = get_model(model_type)
    if model is None:
        return f"âŒ **AI model ({model_type}) is not available**"
    
    try:
        # Model-specific analysis depth
        if model_type == 'smart':
            security_prompt = f"""
**COMPREHENSIVE WEBSITE SECURITY ANALYSIS REQUEST**

Perform a detailed security assessment of the following website scan results.

**ğŸ”’ Security Configuration Status:**
â€¢ **HTTPS Protection:** {'âœ… Properly Configured' if https else 'âŒ Not Implemented - CRITICAL VULNERABILITY'}
â€¢ **Security Issues Detected:** {len(flags)} vulnerabilities identified
â€¢ **HTTP Security Headers:** {len(headers)} headers analyzed

**ğŸš¨ Detailed Vulnerability Assessment:**
{chr(10).join([f'â€¢ **{flag}** - Requires immediate attention' for flag in flags]) if flags else 'â€¢ âœ… No critical security vulnerabilities detected'}

**ğŸ“‹ HTTP Security Headers Analysis:**
{chr(10).join([f'â€¢ **{key}:** `{value}`' for key, value in headers.items()]) if headers else 'â€¢ âš ï¸ No security headers detected'}

Please provide a comprehensive security analysis with these sections:

## ğŸ›¡ï¸ Executive Security Assessment
â€¢ Overall security posture rating
â€¢ Risk level classification (Critical/High/Medium/Low)
â€¢ Executive summary for stakeholders

## ğŸš¨ Critical Vulnerability Analysis
â€¢ Detailed assessment of each security issue
â€¢ Potential attack vectors and exploitation scenarios
â€¢ Business impact assessment
â€¢ OWASP Top 10 correlation

## ğŸ” Security Headers Deep Dive
â€¢ Analysis of implemented security headers
â€¢ Missing critical headers identification
â€¢ Configuration optimization recommendations
â€¢ Browser compatibility considerations

## ğŸ¯ Comprehensive Remediation Strategy
â€¢ Immediate fixes (0-24 hours)
â€¢ Short-term improvements (1-4 weeks)
â€¢ Long-term security architecture (1-6 months)
â€¢ Implementation complexity assessment

## ğŸ’¡ Advanced Security Recommendations
â€¢ Content Security Policy (CSP) implementation
â€¢ Security monitoring and alerting setup
â€¢ Penetration testing recommendations
â€¢ Compliance considerations (PCI DSS, GDPR, etc.)

**ANALYSIS REQUIREMENTS:**
â€¢ Provide technical depth with specific implementation examples
â€¢ Include nginx/Apache configuration snippets
â€¢ Reference security standards and best practices
â€¢ Explain business rationale for each recommendation
"""
        else:  # fast model
            security_prompt = f"""
**QUICK WEBSITE SECURITY SCAN ANALYSIS**

Analyze this website security scan and provide fast, actionable recommendations.

**ğŸ”’ Security Status:**
â€¢ **HTTPS:** {'âœ… Enabled' if https else 'âŒ Missing - FIX IMMEDIATELY'}
â€¢ **Issues Found:** {len(flags)} problems
â€¢ **Headers Present:** {len(headers)} security headers

**ğŸš¨ Problems Found:**
{chr(10).join([f'â€¢ {flag}' for flag in flags]) if flags else 'â€¢ âœ… No major issues detected'}

**ğŸ“‹ Security Headers:**
{chr(10).join([f'â€¢ {key}: {value}' for key, value in headers.items()]) if headers else 'â€¢ No headers found'}

Please provide a quick analysis with these sections:

## ğŸ›¡ï¸ Security Rating
Quick assessment of website security.

## ğŸš¨ Critical Issues
Most important problems to fix first.

## âš¡ Quick Fixes
Specific steps to improve security today.

## ğŸ¯ Implementation Guide
Simple examples and code snippets.

**REQUIREMENTS:**
â€¢ Keep responses practical and actionable
â€¢ Provide specific configuration examples
â€¢ Focus on high-impact, easy wins
â€¢ Use clear, simple language
"""
        
        history = [{"type": "user", "parts": [security_prompt]}]
        return get_chat_response(history, model_type)
        
    except Exception as e:
        return f"âŒ **Website Analysis Error ({model_type} model):** {str(e)}"