"""
ü§ñ Google Gemini Setup Guide for AI-Enhanced Code Generation

QUICK START GUIDE
================================================================================

1. GET GEMINI API KEY
   ‚Ä¢ Visit: https://makersuite.google.com/app/apikey
   ‚Ä¢ Click "Create API Key"  
   ‚Ä¢ Copy your API key

2. SET ENVIRONMENT VARIABLE
   # Windows (PowerShell)
   $env:GOOGLE_API_KEY="your_gemini_api_key_here"
   
   # Windows (Command Prompt)
   set GOOGLE_API_KEY=your_gemini_api_key_here
   
   # Linux/Mac
   export GOOGLE_API_KEY=your_gemini_api_key_here

3. INSTALL DEPENDENCIES
   pip install google-generativeai>=0.3.0

4. TEST INTEGRATION
   python test_gemini_integration.py

DETAILED SETUP
================================================================================

üì¶ DEPENDENCIES
Update your requirements.txt:
```
google-generativeai==0.3.0
python-dotenv==1.0.0
```

üîß ENVIRONMENT CONFIGURATION  
Create or update .env file:
```
GOOGLE_API_KEY=your_gemini_api_key_here
AI_GENERATION_ENABLED=true
AI_MODEL=gemini-1.5-flash
MAX_AI_COST_PER_PROJECT=0.10
```

üí∞ COST COMPARISON: GEMINI vs OPENAI
================================================================================

GOOGLE GEMINI:
‚Ä¢ Cost per 1K tokens: $0.00015 (input), $0.0006 (output)
‚Ä¢ Average cost per project: $0.05 - $0.15
‚Ä¢ Rate limits: 60 requests per minute
‚Ä¢ Context window: 128K tokens
‚Ä¢ Speed: Very fast responses

OPENAI GPT-4:
‚Ä¢ Cost per 1K tokens: $0.03 (input), $0.06 (output) 
‚Ä¢ Average cost per project: $0.50 - $1.50
‚Ä¢ Rate limits: Varies by tier
‚Ä¢ Context window: 128K tokens
‚Ä¢ Speed: Moderate responses

GEMINI ADVANTAGES:
‚úÖ 10-20x cheaper than OpenAI
‚úÖ Faster response times
‚úÖ Generous free tier (1500 requests/day)
‚úÖ Google's latest AI technology
‚úÖ Built-in safety features

üîÑ MIGRATION FROM OPENAI TO GEMINI
================================================================================

OLD (OpenAI):
```python
import openai
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
response = await client.chat.completions.acreate(
    model="gpt-4o-mini", 
    messages=[{"role": "user", "content": prompt}]
)
result = response.choices[0].message.content
```

NEW (Gemini):
```python
import google.generativeai as genai
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
client = genai.GenerativeModel('gemini-1.5-flash')
response = client.generate_content(prompt)
result = response.text
```

üöÄ USAGE EXAMPLES
================================================================================

BASIC AI ANALYSIS:
```python
from ai_enhanced_generator import AIEnhancedGenerator

generator = AIEnhancedGenerator()
plan = await generator.analyze_user_idea("A todo app with priority levels")
print(f"Detected features: {plan.features}")
```

FULL PROJECT GENERATION:
```python
files = await generator.generate_project(
    Path("./my_project"),
    "A chat app with file sharing and emoji reactions", 
    "Team Chat Pro"
)
print(f"Generated {len(files)} files")
```

üéØ GEMINI-SPECIFIC OPTIMIZATIONS
================================================================================

PROMPT ENGINEERING:
‚Ä¢ Gemini responds well to structured JSON requests
‚Ä¢ Use clear examples in prompts
‚Ä¢ Be specific about output format requirements
‚Ä¢ Include safety instructions for code generation

PERFORMANCE TIPS:
‚Ä¢ Use gemini-1.5-flash for fast, cost-effective generation
‚Ä¢ Use gemini-1.5-pro for complex analysis tasks  
‚Ä¢ Cache responses for similar requests
‚Ä¢ Batch multiple small requests when possible

ERROR HANDLING:
‚Ä¢ Handle rate limits gracefully
‚Ä¢ Implement automatic retry with exponential backoff
‚Ä¢ Always have template fallback for reliability
‚Ä¢ Monitor API usage and costs

üõ†Ô∏è INTEGRATION WITH EXISTING SYSTEM
================================================================================

UPDATE main.py:
```python
@app.post("/create-project")
async def create_complete_project_structure(
    idea: str, 
    project_name: str,
    use_ai: bool = True
):
    if use_ai and os.getenv("GOOGLE_API_KEY"):
        # Use Gemini AI generation
        generator = AIEnhancedGenerator()
        result = await generator.generate_project(...)
        return {"method": "gemini-enhanced", "files": result}
    else:
        # Fallback to templates
        generator = ModernProjectGenerator() 
        result = await generator.generate_project(...)
        return {"method": "template-based", "files": result}
```

üìä MONITORING & ANALYTICS
================================================================================

TRACK AI USAGE:
```python
import time
start_time = time.time()
plan = await generator.analyze_user_idea(idea)
duration = time.time() - start_time

# Log metrics
logger.info({
    "ai_provider": "gemini",
    "response_time": duration,
    "tokens_used": len(prompt) + len(response.text),
    "success": True
})
```

COST MONITORING:
‚Ä¢ Track API calls per day/month
‚Ä¢ Monitor token usage patterns  
‚Ä¢ Set up alerts for unusual spending
‚Ä¢ Use free tier limits effectively

üîí SECURITY & BEST PRACTICES
================================================================================

API KEY SECURITY:
‚Ä¢ Never commit API keys to version control
‚Ä¢ Use environment variables or secure vaults
‚Ä¢ Rotate keys regularly
‚Ä¢ Restrict API key permissions

CODE SAFETY:
‚Ä¢ Validate all AI-generated code
‚Ä¢ Maintain array safety patterns
‚Ä¢ Include error handling in generated code
‚Ä¢ Test generated applications thoroughly

RATE LIMITING:
‚Ä¢ Implement client-side rate limiting
‚Ä¢ Use exponential backoff for retries
‚Ä¢ Queue requests during high traffic
‚Ä¢ Cache responses to reduce API calls

üéâ READY TO USE GEMINI!
================================================================================

Your AI-enhanced generator is now configured for Google Gemini:

‚úÖ 10-20x more cost effective than OpenAI
‚úÖ Faster response times  
‚úÖ Same high-quality code generation
‚úÖ Reliable fallback to templates
‚úÖ Production-ready error handling

Next steps:
1. Get your Gemini API key
2. Run the test script
3. Update your main.py integration
4. Deploy with confidence!
"""

def show_setup_status():
    """Show current setup status"""
    import os
    
    print("üîç Current Setup Status")
    print("=" * 30)
    
    # Check API key
    if os.getenv("GOOGLE_API_KEY"):
        print("‚úÖ GOOGLE_API_KEY found in environment")
    else:
        print("‚ùå GOOGLE_API_KEY not set")
        print("   Set with: set GOOGLE_API_KEY=your_key_here")
    
    # Check packages
    try:
        import google.generativeai
        print("‚úÖ google-generativeai package installed")
    except ImportError:
        print("‚ùå google-generativeai not installed")
        print("   Install with: pip install google-generativeai")
    
    try:
        from dotenv import load_dotenv
        print("‚úÖ python-dotenv package installed")
    except ImportError:
        print("‚ùå python-dotenv not installed")
        print("   Install with: pip install python-dotenv")
    
    # Check files
    from pathlib import Path
    files_to_check = [
        "ai_enhanced_generator.py",
        "test_gemini_integration.py"
    ]
    
    for file in files_to_check:
        if Path(file).exists():
            print(f"‚úÖ {file} exists")
        else:
            print(f"‚ùå {file} missing")

if __name__ == "__main__":
    print(__doc__)
    show_setup_status()